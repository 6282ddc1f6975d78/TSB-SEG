import numpy as np
import mlflow
from sklearn.base import BaseEstimator, ClusterMixin

# Try importing tslearn, handle case where it's missing (though required for this strategy)
try:
    from tslearn.clustering import TimeSeriesKMeans
    from tslearn.utils import to_time_series_dataset
    TSLEARN_AVAILABLE = True
except ImportError:
    TSLEARN_AVAILABLE = False

class ChangePointToStateEstimator(BaseEstimator, ClusterMixin):
    """
    Wraps a pre-computed change point detection result and applies clustering 
    to convert segments into states using tslearn's TimeSeriesKMeans.
    
    CRITICAL PERSPECTIVE ON BASELINE APPROACH:
    1. Zero-Padding (used in Euclidean baseline) introduces significant bias, as the distance 
       metric penalizes the difference between signal and zero. 
    2. Euclidean distance is sensitive to phase shifts and length differences.
    3. DTW is preferred for shape matching but computationally heavier.
    
    This implementation uses tslearn to properly handle variable lengths via DTW 
    or consistent formatting for Euclidean.
    
    Parameters
    ----------
    source_run_id : str
        The MLflow run ID where the 'predicted_change_points.npy' is stored.
    n_clusters : int or str, optional
        Number of states. If 'auto', it is inferred from y (ground truth) during fit.
    metric : str, optional
        Metric to use for TimeSeriesKMeans. Options: "dtw", "softdtw", "euclidean".
        Default is "dtw" to handle variable lengths correctly (unlike Euclidean padding).
    """
    def __init__(self, source_run_id=None, n_clusters="auto", metric="dtw"):
        self.source_run_id = source_run_id
        self.n_clusters = n_clusters
        self.metric = metric
        
        self.fitted_change_points_ = None
        self.cluster_model_ = None
        self.n_clusters_ = 2
        self.train_segments_ = None # Store for transductive prediction if needed

    def _load_artifacts(self):
        """Downloads and loads the change points from the source MLflow run."""
        if not self.source_run_id:
            raise ValueError("source_run_id must be provided to load artifacts.")
        
        # Download artifact to local temp dir
        client = mlflow.tracking.MlflowClient()
        try:
            local_path = client.download_artifacts(self.source_run_id, "predicted_change_points.npy")
            cps = np.load(local_path)
            # Ensure unique and sorted
            return np.sort(np.unique(cps))
        except Exception as e:
            print(f"[ChangePointToStateEstimator] Warning: Failed to load artifact for run {self.source_run_id}: {e}")
            return np.array([])

    def _extract_segments(self, X, change_points):
        """
        Extracts raw segments defined by change points and formats them for tslearn.
        
        Returns
        -------
        formatted_segments : np.ndarray
            3D array (n_segments, max_len, n_channels) compatible with tslearn.
        indices_map : list of tuples
            List of (start, end) indices for each segment.
        """
        n_samples = X.shape[0]
        # Ensure 0 and n_samples are included to define segments
        boundaries = np.unique(np.concatenate(([0], change_points, [n_samples])))
        boundaries = np.sort(boundaries)
        
        raw_segments = []
        indices_map = []
        
        for i in range(len(boundaries) - 1):
            start, end = int(boundaries[i]), int(boundaries[i+1])
            if start == end: 
                continue
            
            # Extract raw segment
            segment = X[start:end]
            if segment.ndim == 1:
                segment = segment.reshape(-1, 1) # Ensure (T, D)
                
            raw_segments.append(segment)
            indices_map.append((start, end))
            
        # Convert to tslearn format (pads with NaN by default, keeping length info implicit)
        # Note: If metric="euclidean", tslearn might treat NaNs poorly depending on version, 
        # usually requires equal length or replacement.
        if raw_segments:
            formatted_segments = to_time_series_dataset(raw_segments)
            
            # If Euclidean is requested, NaNs from padding are problematic for standard K-Means.
            # We replace NaNs with 0 to match the user's "padding_and_stack" baseline behavior,
            # (though we noted this is critically flawed).
            # For DTW, tslearn handles variable lengths (often via NaNs).
            if self.metric == "euclidean":
                 formatted_segments = np.nan_to_num(formatted_segments)
        else:
            formatted_segments = np.array([])
            
        return formatted_segments, indices_map

    def fit(self, X, y=None):
        """
        Fits TimeSeriesKMeans on the segments generated by the loaded change points.
        """
        if not TSLEARN_AVAILABLE:
            raise ImportError("tslearn is required for this estimator. Please install it with `pip install tslearn`.")

        # 1. Load previous segmentation
        self.fitted_change_points_ = self._load_artifacts()
        
        # 2. Determine K (number of states)
        if self.n_clusters == "auto" and y is not None:
            self.n_clusters_ = len(np.unique(y))
        elif isinstance(self.n_clusters, int):
            self.n_clusters_ = self.n_clusters
        else:
            self.n_clusters_ = 2 
        if self.n_clusters_ < 2: self.n_clusters_ = 2

        # 3. Extract segments formatted for tslearn
        # formatted_segments is (N, T_max, D)
        self.train_segments_, _ = self._extract_segments(X, self.fitted_change_points_)
        
        if len(self.train_segments_) < self.n_clusters_:
            print(f"[ChangePointToStateEstimator] Warning: Not enough segments ({len(self.train_segments_)}) for {self.n_clusters_} clusters.")
            self.cluster_model_ = None
            return self

        # 4. Initialize and Fit TimeSeriesKMeans
        # verbose=0 to avoid cluttering MLflow logs
        self.cluster_model_ = TimeSeriesKMeans(
            n_clusters=self.n_clusters_,
            metric=self.metric,
            max_iter=50,
            n_init=3, # Lower n_init for speed if using DTW
            random_state=0,
            verbose=0
        )
        
        self.cluster_model_.fit(self.train_segments_)
        return self

    def predict(self, X):
        """
        Predicts state labels for the time series X.
        """
        if self.fitted_change_points_ is None:
             raise RuntimeError("The estimator has not been fitted or artifacts not loaded.")
        
        n_samples = X.shape[0]
        y_pred = np.zeros(n_samples, dtype=int)
        
        formatted_segments, indices_map = self._extract_segments(X, self.fitted_change_points_)
        
        if self.cluster_model_ is None or len(formatted_segments) == 0:
            return y_pred
        
        # Predict state for each segment
        # In tslearn, predict() assigns closest centroid
        try:
             segment_labels = self.cluster_model_.predict(formatted_segments)
        except Exception as e:
            # Fallback if prediction fails (e.g. dimension mismatch issues)
            print(f"[ChangePointToStateEstimator] Prediction failed: {e}")
            segment_labels = np.zeros(len(formatted_segments))

        # Broadcast back to time points
        for k, (start, end) in enumerate(indices_map):
            if k < len(segment_labels):
                y_pred[start:end] = segment_labels[k]
            
        return y_pred
